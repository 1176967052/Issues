#### 操作系统

1. 进程与线程的本质区别、以及各自的使用场景

   区别：从调度单位，并发性，拥有资源，独立性，系统开销等方面比较
   1. 进程是系统分配资源的基本单位，是对应用程序提供的一种抽象，是拥有一个执行流，或多个执行流的线程组，是一个能独立运行的基本单位。线程是运行在进程上下文中的逻辑流，是 CPU 使用的最小单元，并且有自己的线程上下文，不同线程共享同一进程的除栈之外的虚拟地址空间，比进程上下文更轻量级。创建速度更快，线程间切换的代价更低(不用切换地址空间，不用更改寄存器，不用刷新 TLB),方便数据共享。
   2. 多进程的优点：（1）编程相对容易；通常不需要考虑锁和同步资源的问题。（2）一个进程崩溃了不会影响其他进程。 （3）有内核保证的隔离：数据和错误隔离。采用多进程架构的程序一般可以做到一定程度的自恢复；（master守护进程监控所有worker进程，发现进程挂掉后将其重启）。
      多线程的优点：（1）创建速度快，方便高效的数据共享，多线程间可以共享同一虚拟地址空间 （2）较轻的上下文切换开销 - 不用切换地址空间，不用更改寄存器，不用刷新TLB。（3）提供非均质的服务。它能有效降低“简单任务被复杂任务压住”的概率。
    
   使用场景：
   1. 线程的使用场景：（1）线程间有数据共享，并且数据是需要修改的（2）提供非均质的服务（有优先级任务处理）事件响应有优先级。（3）需要频繁创建销毁优先使用线程。（4）需要大量计算的优先使用线程。
   2. 进程的使用场景：（1）相关性较弱使用进程。 （2）可能要扩展到多机分布使用进程，多核分布使用线程
   
2. 进程的状态
   1. 就绪状态
   2. 执行状态
   3. 阻塞状态
   
   就绪->执行：
   处于就绪状态的进程，当进程调度程序为止分配了处理机后，该进程就由就绪状态转变为执行状态。
   
   执行->就绪：
   处于执行状态的进程在其执行过程中，因分配给它的一个时间片已用完而不得不让出处理机，于是进程从执行状态转变成就绪状态。
   
   执行->阻塞：
   正在执行的进程因等待某种事件发生而无法继续执行时，便从执行状态变成阻塞状态。
   
   阻塞->就绪：
   处于阻塞状态的进程，若其等待的事件已经发生，于是进程由阻塞状态转变为就绪状态。 

3. 进程调度算法
   1. 时间片轮转调度算法（RR）：给每个进程固定的执行时间，根据进程到达的先后顺序让进程在单位时间片内执行，执行完成后便调度下一个进程执行，时间片轮转调度不考虑进程等待时间和执行时间，属于抢占式调度。优点是兼顾长短作业；缺点是平均等待时间较长，上下文切换较费时。适用于分时系统。
   
   2. 先来先服务调度算法（FCFS）：根据进程到达的先后顺序执行进程，不考虑等待时间和执行时间，会产生饥饿现象。属于非抢占式调度，优点是公平，实现简单；缺点是不利于短作业。
   
   3. 优先级调度算法（HPF）：在进程等待队列中选择优先级最高的来执行。常被用于批处理系统中，还可用于实时系统中。
   
   4. 多级反馈队列调度算法：将时间片轮转与优先级调度相结合，把进程按优先级分成不同的队列，先按优先级调度，优先级相同的，按时间片轮转。优点是兼顾长短作业，有较好的响应时间，可行性强，适用于各种作业环境。
   
   5. 高响应比优先调度算法：根据“响应比=（进程执行时间+进程等待时间）/ 进程执行时间”这个公式得到的响应比来进行调度。高响应比优先算法在等待时间相同的情况下，作业执行的时间越短，响应比越高，满足段任务优先，同时响应比会随着等待时间增加而变大，优先级会提高，能够避免饥饿现象。优点是兼顾长短作业，缺点是计算响应比开销大，适用于批处理系统。     

4. 线程实现的方式。
   1. 用户级线程实现方式
   
      有关线程管理的所有工作都由应用程序完成，内核意识不到多线程的存在。对于一个进程，可能有成千上万个用户级线程，但是它们对系统资源没有影响。运行时库调度并分派这些线程。库调度器从进程的多个线程中选择一个线程，然后该线程和该进程与一个内核线程关联起来。内核线程将被操作系统调度器指派到处理器内核。用户级线程是一种”多对一”的线程映射。
    
   2. 内核级线程实现
   
      内核线程建立和销毁都是在内核的支持下运行，由操作系统负责管理，通过系统调用完成的。应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口。内核为进程及其内部的每个线程维护上下文信息，调度也是在内核基于线程架构的基础上完成。
      
   3. 组合线程
   
      使用组合方式的多线程实现, 线程创建完全在用户空间中完成，线程的调度和同步也在应用程序中进行。一个应用程序中的多个用户级线程被映射到一些（小于或等于用户级线程的数目）内核级线程上。
      
5. 协程
   协程不是进程，也不是线程，它就是一个函数，一个特殊的函数——可以在某个地方挂起，并且可以重新在挂起处继续运行。所以说，协程与进程、线程相比，不是一个维度的概念。
   
   一个线程内的多个协程的运行是串行的。如果有多核CPU的话，多个进程或一个进程内的多个线程是可以并行运行的，但是一个线程内的多个协程却绝对串行的，无论有多少个CPU（核）。这个比较好理解，毕竟协程虽然是一个特殊的函数，但仍然是一个函数。一个线程内可以运行多个函数，但是这些函数都是串行运行的。当一个协程运行时，其他协程必须挂起。
   
   协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。
   
   最大的优势就是协程极高的执行效率，第二大优势就是不需要多线程的锁机制

6. 常见进程同步问题。

   临界资源（临界区）：指一次只能允许一个进程使用的共享资源称为临界资源；
   
   同步：指为完成某种任务而建立的两个和多个进程，这些进程在合作的过程中需要协调工作次序进行有序的访问而出现等待所产生的制约关系。
   
   互斥：指两个或多个进程访问临界资源时只能一个进程访问，其他进程等待的一种相互制约的关系。
   
   信号量：本身是一个计数器，使用P，V两个操作来实现计数的减与加，当计数不大于0时，则进程进入睡眠状态，它用于为多个进程提供共享数据对象的访问。
   
   互斥量：如果信号量只存在两个状态，那就不需要计数了，可以简化为加锁与解锁两个功能，这就是互斥量。
   
   1. 生产者与消费者问题
   
      生产者与消费者进程对缓冲区的访问是互斥关系，而生产者与消费者本身又存在同步关系，即必须生成之后才能消费。因而对于缓冲区的访问设置一个互斥量，再设置两个信号量一个记录空闲缓冲区单元，一个记录满缓冲区单元来实现生产者与消费者的同步。
   
   2. 读者与写者问题：有读者与写者两个并发进程共享一个数据，两个或以上的读进程可以访问数据，但是一个写者进程访问数据与其他进程都互斥。
      
      读者与写者是互斥关系，写者与写者是互斥关系，读者与读者是同步关系。因而需要一个互斥量实现读与写和写与写互斥，一个读者的访问计数和实现对计数的互斥。
   
   3. 哲学家就餐问题：一张圆桌上坐着五名哲学家，每两名哲学家之间的桌子摆一根筷子，哲学家只有同时拿起左右两根筷子时才可以用餐，用餐完了筷子放回原处。
      
      这里五名哲学家就是五个进程，五根筷子是需要获取的资源。可以定义互斥数组用于表示五根筷子的互斥访问，为了防止哲学家各取一根筷子出现死锁，需要添加一定的限制条件。一种方法是限制仅当哲学家左右筷子均可以用时，才拿起筷子，这里需要一个互斥量来限制获取筷子不会出现竞争。
          
7. 进程通信方法的特点以及使用场景。
   
   进程间通信（IPC，InterProcess Communication）的主要方式包括：管道、FIFO、消息队列、信号量、共享内存以及socket。
   
   1. 管道： 无名管道只能在具有公共祖先的两个进程之间使用，通常，一个管道由一个进程创建，在进程调用fork之后，这个管道就能在父进程和子进程之间使用了。         
   2. FIFO：FIFO即为命名管道，与无名管道不同的是，其可以在不相关的程序之间交换数据。FIFO其实是一种文件类型，创建FIFO类似于创建文件。
      FIFO有两种用途：
      1. shell命令使用FIFO将数据从一条管道传送到另一条管道时，无须创建中间的临时文件。
      2. 客户进程-服务器进程应用程序中，FIFO用作汇聚点，在客户进程和服务器进程二者之间传递数据。     
   3. 消息队列：消息队列是消息的链接表，存储在内核中，有消息队列标识符标识，我们并不一定以先进先出的顺序取消息，可以按照消息的类型字段取消息。
   4. 信号量：它是一个计数器，用于为多个进程提供共享数据对象的访问。
      1. 测试控制该资源的信号量；
      2. 若此信号量的值为正，则进程可以使用该资源。在这种情况下，进程会将信号量值减1，表示它使用了一个资源单位；
      3. 否则，若此信号量的值为0，则进程进入休眠状态，知道信号量的值大于0。进程被唤醒后，返回步骤1。
   5. 共享存储：共享存储允许两个或多个进程共享一个给定的存储区
   
   使用场景：
   1. 如果用户传递的信息较少，或者只是为了出发某些行为。信号是一种简洁有效的通信方式。但若是进程间要求传递的信息量较大或者存在数据交换的要求，就需要考虑别的通信方式了。
   
   2. 无名管道与有名管道的区别在于单向通信以及有关联的进程。
   
   3. 消息队列允许任意进程通过共享队列来进行进程间通信。并由系统调用函数来实现消息发送和接收之间的同步。从而使得用户在使用消息缓冲进行通信时不再需要考虑同步问题，使用相对方便。
      但是消息队列中信息的复制需要耗费CPU时间，不适宜信息量大或频繁操作的场合。
   
   4. 消息队列与管道方式的区别在于，消息队列可以实现多对多，并需要在内存中实现，而管道可以在内存或磁盘上实现。
   
   5. 共享内存无须复制，信息量大是其最大的优势。但是需要考虑同步问题。

8. 死锁必要条件、解决死锁策略，能写出和分析死锁的代码，能说明在数据库管理系统或者 Java 中如何解决死锁。
   
   死锁：如果一个进程集合中的每个进程都在等待只能由该进程集合中的其他进程才能引发的事件，那么该进程集合就是死锁的。
   
   死锁的条件（四个同时满足）：
   
   (1)互斥：每个资源要么已经分配给一个进程，要么就是可用的；
   
   (2)占有和等待：已经得到的某个资源的进程请求新的资源；
   
   (3)不可抢占：已经分配的资源不能强制被抢占，只能进程自己显式的释放；
   
   (4)环路等待：存在一种进程资源的循环等待链。
   
   死锁的处理策略：
   
   (1)死锁预防：破坏死锁的四个条件之一
   
   　　破环互斥条件：允许资源共享
   
   　　破环占有和等待条件：采用预先静态分配
   
   　　不可抢占：请求新资源得不到时，释放已经保持占有的资源，待以后重新申请
   
   　　环路等待：采用顺序资源分配法
   
   (2)死锁避免：死锁避免事先预防策略，但是是采用资源动态分配的过程中，防止系统进入不安全状态，以避免死锁。
   
   　　银行家算法：可利用资源矢量Available，请求矢量Request
   
   　　　　　　　　最大需求矩阵Max，分配矩阵Allocation,需求矩阵Need
   
   　　　　　　　　通过Need=Max-Allocation获得每个进程需要的各类资源数Need矩阵
   
   　　　　　　　　一般每个进程请求矢量应该小于等于Need的值
   
   　　　　　　　　试探分配：Available=Avaliable-Request
   
   　　　　　　　　　　　　　Allocate相对应的项=Allocate相对应的项+Request
   
   　　　　　　　　　　　　　Need相对应的项=Need相对应的项-Request
   
   　　　　　　　　安全性算法：检查资源分配后，系统是否属于安全状态，如果安全才正式分配资源，否则作废。一般通过安全性算法推算一个安全序列（核心）。　　
   
   (3)死锁检测与解除：
   
   　　检测死锁：利用死锁原理化简资源分配图检测死锁的存在
   
   　　死锁解除：资源剥夺、撤销进程、进程回退

9. 虚拟内存的作用，分页系统实现虚拟内存原理。
   虚拟内存指将内存中暂时不需要的部分写入硬盘，看上去硬盘扩展了内存的容量，所以叫做“虚拟”内存。使用虚拟内存，应用程序可以使用比实际物理内存更大的内存空间。可以认为这个更大的内存空间就在硬盘上，只有将某一部分需要被用到时，才被写入真实内存；当它暂时不再被用到时，又被写回硬盘。
   1. 使用虚拟地址可以更加高效的使用物理内存。  
   2. 使用虚拟地址可以使内存的管理更加便捷。
   3. 为了安全性的考虑
   
   由程序产生的地址称为虚拟地址，它们构成了一个虚拟地址空间。在没有虚拟内存的计算机上，系统直接把虚拟地址送到内存总线上，读写操作使用具有相同地址的物理内存字；而在使用虚拟内存的情况下，虚拟地址不是被直接送到内存总线上，而是被送到内存管理单元（Memory Management Unit，MMU），MMU把虚拟地址映射为物理内存地址。
   虚拟地址空间按照固定大小划分成被称为页面（page）的若干单元。在物理内存中对应的单元称为页框。页面和页框的大小通常是一样的。
   
   
10. 页面置换算法的原理，特别是 LRU 的实现原理，最好能手写，再说明它在 Redis 等作为缓存置换算法。
    假设某一时刻内存页帧已经被写满了，但这时又需要将一个页写到物理内存中，就需要将原本在物理内存中的某一页换出来。如果置换不当，就会导致刚刚被换出到硬盘的页又要被写回内存，减慢系统运行的速度。页面置换算法就是考虑将哪一页换出来以获得优良性能的方法。
    
    算法：先进先出，最近最少使用。。
    
    LRU的java实现
    
    LinkedHashMap存储数据是有序的，而且分为两种：插入顺序和访问顺序。这里accessOrder设置为false，表示不是访问顺序而是插入顺序存储的，这也是默认值，表示LinkedHashMap中存储的顺序是按照调用put方法插入的顺序进行排序的。
    
    
11. 比较分页与分段的区别。
12. 分析静态链接的不足，以及动态链接的特点。
    
#### 计算机网络 

1. 各层协议的作用，以及 TCP/IP 协议的特点。

2. 以太网的特点，以及帧结构。

3. 集线器、交换机、路由器的作用，以及所属的网络层。

4. IP 数据数据报常见字段的作用。

5. ARP 协议的作用，以及维护 ARP 缓存的过程。

6. ICMP 报文种类以及作用；和 IP 数据报的关系；Ping 和 Traceroute 的具体原理。

7. UDP 与 TCP 比较，分析上层协议应该使用 UDP 还是 TCP。

8. 理解三次握手以及四次挥手具体过程，三次握手的原因、四次挥手原因、TIME_WAIT 的作用。

9. 可靠传输原理，并设计可靠 UDP 协议。

10. TCP 拥塞控制的作用，理解具体原理。

11. DNS 的端口号；TCP 还是 UDP；作为缓存、负载均衡。

#### http

1.GET 与 POST 比较：作用、参数、安全性、幂等性、可缓存。

2. HTTP 状态码。

3. Cookie 作用、安全性问题、和 Session 的比较。

4. 缓存 的 Cache-Control 字段，特别是 Expires 和 max-age 的区别。ETag 验证原理。

5. 长连接与短连接原理以及使用场景，流水线。

6. HTTP 存在的安全性问题，以及 HTTPs 的加密、认证和完整性保护作用。

7. HTTP/1.x 的缺陷，以及 HTTP/2 的特点。

8. HTTP/1.1 的特性。

9. HTTP 与 FTP 的比较。

#### Socket
1. 五种 IO 模型的特点以及比较。

2. select、poll、epoll 的原理、比较、以及使用场景；epoll 的水平触发与边缘触发。

#### Mysql

1. 手写 SQL 语句，特别是连接查询与分组查询。

2. 连接查询与子查询的比较。

3. drop、delete、truncate 比较。

4. 视图的作用，以及何时能更新视图。

5. 理解存储过程、触发器等作用。

6. ACID 的作用以及实现原理。

7. 四大隔离级别，以及不可重复读和幻影读的出现原因。

8. 封锁的类型以及粒度，两段锁协议，隐式和显示锁定。

9. 乐观锁与悲观锁。

10. MVCC 原理，当前读以及快照读，Next-Key Locks 解决幻影读。

11. 范式理论。

12. SQL 与 NoSQL 的比较。

13. B+ Tree 原理，与其它查找树的比较。

14. MySQL 索引以及优化。

15. 查询优化。

16. InnoDB 与 MyISAM 比较。

17. 水平切分与垂直切分。

18. 主从复制原理、作用、实现。

19. redo、undo、binlog 日志的作用。

#### Redis
1. 字典和跳跃表原理分析。

2. 使用场景。

3. 与 Memchached 的比较。

4. 数据淘汰机制。

5. RDB 和 AOF 持久化机制。

6. 事件驱动模型。

7. 主从复制原理。

8. 集群与分布式。

9. 事务原理。

10. 线程安全问题。

#### 面向对象
1. 面向对象三大特性

2. 设计原则

#### 设计模式

1. 设计模式的作用。

2. 手写单例模式，特别是双重检验锁以及静态内部类。

3. 手写工厂模式。

4. 理解 MVC，结合 SpringMVC 回答。

5. 理解代理模式，结合 Spring 中的 AOP 回答。

6. 分析 JDK 中常用的设计模式，例如装饰者模式、适配器模式、迭代器模式等。

#### spring


#### mq

#### 分布式

#### 微服务

#### JVM

#### 并发编程

#### java8/jdk

#### ORM （MyBatis，spring data jpa）

#### 

      
   
   
      