1. redis会丢数据吗？
   会，1. 淘汰策略 2. 设置过期时间
2. redis持久化方式及原理
   Redis为持久化提供了两种方式：
   
   1. RDB：在指定的时间间隔能对你的数据进行快照存储。
      save 900 1 表示900s内如果有1条是写入命令，就触发产生一次快照，可以理解为就进行一次备份
      save 300 10 表示300s内有10条写入，就产生快照
      
      原理：
      save：会阻塞当前Redis服务器，直到持久化完成，线上应该禁止使用。
      bgsave：该触发方式会fork一个子进程，由子进程负责持久化过程，因此阻塞只会发生在fork子进程的时候。从节点全量复制时，主节点发送rdb文件给从节点完成复制操作，主节点会触发 bgsave；
      
   2. AOF：记录每次对服务器写的操作,当服务器重启的时候会重新执行这些命令来恢复原始的数据。
      appendfsync everysec 它其实有三种模式:
      
      always：把每个写命令都立即同步到aof，很慢，但是很安全
      everysec：每秒同步一次，是折中方案
      no：redis不处理交给OS来处理，非常快，但是也最不安全

3. redis故障恢复
   通过RDB或AOF，都可以将redis内存中的数据持久化到磁盘上来，然后可以将数据备份到阿里云，如果redis挂了，服务器中内存和磁盘的数据就都丢了，这时候可以将阿里云中的备份文件拷贝至指定目录下，然后重启redis，redis就会自动根据持久化数据文件去恢复内存中的数据，继续对外提供服务。如果同时室友了RDB和AOF两种持久化机制，那么在重启的时间建议使用AOF的方式重新构建数据，因为AOF中的数据更加完整。
4. redis缓存击穿的解决方案
   缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力
   解决：
   1. 设置热点数据永远不过期。
   2. 加互斥锁   
5. redis倾斜问题
   访问倾斜和数据倾斜
   访问倾斜：Hot key，即热点 key，指的是在一段时间内，该 key 的访问量远远高于其他的 redis key， 导致大部分的访问流量在经过 proxy 分片之后，都集中访问到某一个 redis 实例上。hot key 通常在不同业务中，存储着不同的热点信息。
   
   1. 使用本地缓存
   在 client 端使用本地缓存，从而降低了redis集群对hot key的访问量，但是同时带来两个问题：1、如果对可能成为 hot key 的 key 都进行本地缓存，那么本地缓存是否会过大，从而影响应用程序本身所需的缓存开销。2、如何保证本地缓存和redis集群数据的有效期的一致性。
   针对这两个问题，先不展开讲，先将第二个解决方案。
   
   2. 利用分片算法的特性，对key进行打散处理
   我们知道 hot key 之所以是 hot key，是因为它只有一个key，落地到一个实例上。所以我们可以给hot key加上前缀或者后缀，把一个hotkey 的数量变成 redis 实例个数N的倍数M，从而由访问一个 redis key 变成访问 N * M 个redis key。
   N*M 个 redis key 经过分片分布到不同的实例上，将访问量均摊到所有实例。通过一个大于等于 1 小于 M * N 的随机数，得到一个 tmp key，程序会优先访问tmp key，在得不到数据的情况下，再访问原来的 hot key，并将 hot key的内容写回 tmp key。值得注意的是，tmp key的过期时间是 hot key 的过期时间加上一个较小的随机正整数，保证在 hot key 过期时，所有 tmp key 不会同时过期而造成缓存雪崩。这是一种通过坡度过期的方式来避免雪崩的思路，同时也可以利用原子锁来写入数据就更加的完美，减小db的压力。
   
   
   数据量倾斜：big key ，即数据量大的 key ，由于其数据大小远大于其他key，导致经过分片之后，某个具体存储这个 big key 的实例内存使用量远大于其他实例，造成，内存不足，拖累整个集群的使用。
   解决：对 big key 进行拆分
   
   如何发现 hot key，big key
   1. 事前-预判
   2. 事中-监控和自动处理
   3. 事后多长教训
 
6. redis pipeline模式 
   redis客户端执行一条命令分4个过程：发送命令－〉命令排队－〉命令执行－〉返回结果
   这个过程称为Round trip time(简称RTT, 往返时间)，mget mset(批量设置，获取)有效节约了RTT，但大部分命令（如hgetall命令用于返回哈希表中，所有的字段和值，并没有mhgetall）不支持批量操作，需要消耗N次RTT ，这个时候需要pipeline来解决这个问题
   
   使用了pipeline执行N条命令，发送N条命令，统一单线程执行完后再返回
   批量 减少IO
   pipeline通过减少客户端与redis的通信次数来实现降低往返延时时间，而且Pipeline 实现的。就是说可以把多条指令放入到一个tcp报文一起发送，server则可以将三条命令的处理结果放到一个tcp报文返回。主要是TCP连接中减少了“交互往返”的时间。
   
   一次 pipeline：
   1. 客户端进程调用write将消息写到操作系统内核为套接字分配的发送缓冲send buffer。
   2. 客户端操作系统内核将发送缓冲的内容发送到网卡，网卡硬件将数据通过「网际路由」送到服务器的网卡。
   3. 服务器操作系统内核将网卡的数据放到内核为套接字分配的接收缓冲recv buffer。
   4. 服务器进程调用read从接收缓冲中取出消息进行处理。
   5. 服务器进程调用write将响应消息写到内核为套接字分配的发送缓冲send buffer。
   5. 服务器操作系统内核将发送缓冲的内容发送到网卡，网卡硬件将数据通过「网际路由」送到客户端的网卡。
   7. 客户端操作系统内核将网卡的数据放到内核为套接字分配的接收缓冲recv buffer。
   8. 客户端进程调用read从接收缓冲中取出消息返回给上层业务逻辑进行处理。
   结束。
   其中步骤 5~8 和 1~4 是一样的，只不过方向是反过来的，一个是请求，一个是响应。
   
   
   原生批命令(mset, mget)与Pipeline对比
   1. 原生批命令是原子性，pipeline是非原子性
   (原子性概念:一个事务是一个不可分割的最小工作单位,要么都成功要么都失败。原子操作是指你的一个业务逻辑必须是不可拆分的. 处理一件事情要么都成功，要么都失败，原子不可拆分)
   
   2. 原生批命令一命令多个key, 但pipeline支持多命令（存在事务），非原子性
   3. 原生批命令是服务端实现，而pipeline需要服务端与客户端共同完成
   
   pipeline是多条命令的组合，为了保证它的原子性，redis提供了简单的事务,不支持事务回滚:
   1. 一组需要一起执行的命令放到multi和exec两个命令之间，其中multi代表事务开始，exec代表事务结束。
   2. 停止事务discard
   3. 命令错误，语法不正确，导致事务不能正常结束
   4. 运行错误，语法正确，但类型错误，事务可以正常结束
   5. 使用watch后， multi失效，事务失效
      WATCH的机制是：在事务EXEC命令执行时，Redis会检查被WATCH的key，只有被WATCH的key从WATCH起始时至今没有发生过变更，EXEC才会被执行。如果WATCH的key在WATCH命令到EXEC命令之间发生过变化，则EXEC命令会返回失败。
   
7. 跳表
   1. 很多层结构,level是通过一定的概率随机产生的
   2. 每层都是有序链表，默认升序
   3. 最底层的链表包含所有元素
   4. 一个元素出现在上层level，则下层level也会包含该元素
   5. 每个节点包含两个指针，一个指向同一链表的下一个元素，一个指向下一层的元素   
          