1. 布隆过滤器
2. 一致性hash
3. 负载均衡原理
4. 分布式锁常用方案 redis setnx，分布式锁redis实现方式，存在的问题，优化方案
   首先明确一点，有人可能会问是否可以考虑采用ReentrantLock来实现，但是实际上去实现的时候是有问题的，ReentrantLock的lock和unlock要求必须是在同一线程进行，而分布式应用中，lock和unlock是两次不相关的请求，因此肯定不是同一线程，因此导致无法使用ReentrantLock。
   1. 基于数据库表做乐观锁，用于分布式锁。
   2. 使用redis的setnx()、expire()方法，用于分布式锁
      SET lock_key random_value NX PX 5000
      
      值得注意的是：
      random_value 是客户端生成的唯一的字符串。
      NX 代表只在键不存在时，才对键进行设置操作。
      PX 5000 设置键的过期时间为5000毫秒。
      解锁的过程就是将Key键删除。但也不能乱删，不能说客户端1的请求将客户端2的锁给删除掉。这时候random_value的作用就体现出来。
      
      为了保证解锁操作的原子性，我们用LUA脚本完成这一操作。先判断当前锁的字符串是否与传入的值相等，是的话就删除Key，解锁成功。
      
      首先说明一下setnx()命令，setnx的含义就是SET if Not Exists，其主要有两个参数 setnx(key, value)。该方法是原子的，如果key不存在，则设置当前key成功，返回1；如果当前key已经存在，则设置当前key失败，返回0。但是要注意的是setnx命令不能设置key的超时时间，只能通过expire()来对key设置。
      具体的使用步骤如下:
      1. setnx(lockkey, 1)  如果返回0，则说明占位失败；如果返回1，则说明占位成功
      
      2. expire()命令对lockkey设置超时时间，为的是避免死锁问题。
      
      3. 执行完业务代码后，可以通过delete命令删除key。
      
      这个方案其实是可以解决日常工作中的需求的，但从技术方案的探讨上来说，可能还有一些可以完善的地方。比如，如果在第一步setnx执行成功后，在expire()命令执行成功前，发生了宕机的现象，那么就依然会出现死锁的问题，所以如果要对其进行完善的话，可以使用redis的setnx()、get()和getset()方法来实现分布式锁。   
       
   2. 使用redis的setnx()、get()、getset()方法，用于分布式锁。
      这个方案的背景主要是在setnx()和expire()的方案上针对可能存在的死锁问题，做了一版优化。
      那么先说明一下这三个命令，对于setnx()和get()这两个命令，相信不用再多说什么。那么getset()命令？这个命令主要有两个参数 getset(key，newValue)。该方法是原子的，对key设置newValue这个值，并且返回key原来的旧值。假设key原来是不存在的，那么多次执行这个命令，会出现下边的效果：
      
      1. getset(key, "value1")  返回nil   此时key的值会被设置为value1
      
      2. getset(key, "value2")  返回value1   此时key的值会被设置为value2
      
      3. 依次类推！
      
      介绍完要使用的命令后，具体的使用步骤如下：
      
      1. setnx(lockkey, 当前时间+过期超时时间) ，如果返回1，则获取锁成功；如果返回0则没有获取到锁，转向2。
      
      2. get(lockkey)获取值oldExpireTime ，并将这个value值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向3。
      
      3. 计算newExpireTime=当前时间+过期超时时间，然后getset(lockkey, newExpireTime) 会返回当前lockkey的值currentExpireTime。
      
      4. 判断currentExpireTime与oldExpireTime 是否相等，如果相等，说明当前getset设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。
      
      5. 在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行delete释放锁；如果大于锁设置的超时时间，则不需要再锁进行处理。
   3. 使用zookeeper，用于分布式锁。
      使用zookeeper节点名称唯一性来做分布式锁这个方案的缺点。比如，当许多线程在等待一个锁时，如果锁得到释放的时候，那么所有客户端都被唤醒，但是仅仅有一个客户端得到锁。在这个过程中，大量的线程根本没有获得锁的可能性，但是也会引起大量的上下文切换，这个系统开销也是不小的，对于这样的现象有一个专业名词，称之为“惊群效应”。
      所谓顺序节点，假如我们在/myDisLocks/目录下创建3个节点，zookeeper集群会按照发起创建的顺序来创建节点，节点分别为/myDisLocks/0000000001、/myDisLocks/0000000002、/myDisLocks/0000000003。
      所谓临时节点，临时节点由某个客户端创建，当客户端与zookeeper集群断开连接，则该节点自动被删除。
      watcher机制：任何一个连接zookeeper的客户端可以通过watcher机制关注自己感兴趣的节点的增删改查，当这个节点发生增删改查的操作时，会“广播”自己的消息，所有对此感兴趣的节点可以在收到这些消息后，根据自己的业务需要执行后续的操作。
      
      1. 每个业务线程调用create()方法创建名为“/myDisLocks/thread”的节点，需要注意的是，这里节点的创建类型需要设置为EPHEMERAL_SEQUENTIAL，即节点类型为临时顺序节点。此时/myDisLocks节点下会出现诸如/myDisLocks/thread0000000001、/myDisLocks/thread0000000002、/myDisLocks/thread0000000003这样的子节点。
      
      2. 每个业务线程调用getChildren(“myDisLocks”)方法来获取/myDisLocks这个节点下所有已经创建的子节点。
      
      3. 每个业务线程获取到所有子节点的路径之后，如果发现自己在步骤1中创建的节点的尾缀编号是所有节点中序号最小的，那么就认为自己获得了锁。
      
      4. 如果在步骤3中发现自己并非是所有子节点中序号最小的，说明自己还没有获取到锁。使用watcher机制监视比自己创建节点的序列号小的节点（比自己创建的节点小的最大节点），进入等待。比如，如果当前业务线程创建的节点是/myDisLocks/thread0000000003，那么在没有获取到锁的情况下，他只需要监视/myDisLocks/thread0000000002的情况。只有当/myDisLocks/thread0000000002获取到锁并释放之后，当前业务线程才启动获取锁，这样可以避免一个业务线程释放锁之后，其他所有线程都去竞争锁，引起不必要的上下文切换，最终造成“惊群现象”。
      
      5. 释放锁的过程相对比较简单，就是删除自己创建的那个子节点即可。
      
   高可用的Redis锁
   基于Redis的Redisson分布式可重入锁RLock Java对象实现了java.util.concurrent.locks.Lock接口。
   如果负责储存这个分布式锁的Redisson节点宕机以后，而且这个锁正好处于锁住的状态时，这个锁会出现锁死的状态。为了避免这种情况的发生，Redisson内部提供了一个监控锁的看门狗，它的作用是在Redisson实例被关闭前，不断的延长锁的有效期。默认情况下，看门狗的检查锁的超时时间是30秒钟，也可以通过修改Config.lockWatchdogTimeout来另行指定
   另外Redisson还通过加锁的方法提供了leaseTime的参数来指定加锁的时间。超过这个时间后锁便自动解开了。
   RLock对象完全符合Java的Lock规范。也就是说只有拥有锁的进程才能解锁，其他进程解锁则会抛出IllegalMonitorStateException错误。但是如果遇到需要其他进程也能解锁的情况，请使用分布式信号量Semaphore 对象.   
5. 如何保证服务的高可用  幂等，限流，降级，自动故障转移  https  请求有效期：签名+时间戳
   请求接口的参数中添加时间戳
   每次客户端发送请求时，获取当前时间戳，当参数一同发送到服务器，服务器拦截该请求，获取服务器上当前时间戳和客户端请求中的时间戳进行比较，如果两个时间戳相差超过60s的话就认定为非法请求，因为一般一次正常的http请求发送到服务器不会超过60秒，所以可以这样做。
   请求接口的参数中添加sign签名，使用签名验证，保证每次请求时候签名只能使用一次。
   客户端和服务器端约定一个生成签名串的算法，可以由客户端ip+加密密钥+当前时间戳进行MD5加密生成，前端生成签名串后，跟随参数一起发送到后台解密，并将该签名串保存在redis中，下次请求的时候，先在redis中取查找是否有该签名串，如果有，则说明是非正常请求，这时候就可以认定为非法操作。
 
7. zookeeper及底层算法，一致性算法Paxos
   二阶段提交算法的简称是2PC(Two Phase Commit),是计算机网络尤其是在数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务处理过程中能够保持原子性和一致性而设计的一种算法。通常，二阶段提交协议也被认为是一种一致性协议，用来保证分布式系统数据的一致性。目前，绝大部分的关系型数据库都是采用二阶段提交协议来完成分布式事务处理的，利用该协议能够非常方便地完成所有分布式事务参与者的协调，统一决定事务的提交或回滚，从而能够有效地保证分布式数据一致性，因此二阶段提交协议被广泛地应用在许多分布式系统中。
   阶段一：提交事务请求+执行事务
   
   a.事务询问
   
   协调者向所有参与者发送事务内容，询问各个参与者是否可以执行事务提交操作，并且等待各个事务参与者的响应
   
   b.执行事务
   
   各个参与者执行事务操作，并将事务操作记入事务日志中
   
   c.各个参与者向协调者反馈事务询问的响应
   
   在此过程中，如果参与者向协调者反馈了yes响应，则表示事务可以执行。如果参与者向协调者反馈了No响应，表示事务不可执行。因此二阶段提交算法阶段一是协调者组织参与者参加了一次执行事务的投票，因此阶段一也可以称为"投票阶段"。
   
   ​ 阶段二：事务提交
   
   在阶段二中，协调者会根据参与者的反馈情况来决定最终是否可以进行事务提交操作，正常情况下，包含以下两种可能。
   
   执行事务提交
   
   加入所有参与者向协调者反馈的都是ACK的YES响应，那么就会执行事务提交。
   
   1.发送提交请求
   
   协调者向所有参与者节点发送commit请求
   
   2.事务提交
   
   参与者接收到commit请求后，会正式执行事务提交操作。并在提交完成之后释放整个事务执行期间占用的事务资源。
   
   3.反馈事务的提交结果
   
   参与者在完成事务提交之后，向协调者发送ACK确认消息
   
   4.事务完成
   
   协调者接收到所有的参与者的ACK消息，完成事务提交
   
   事务中断
   
   假如任何一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。
   
   发送回滚请求。
   协调者向所有参与者节点发出Rollback请求。
   
   事务回滚。
   
   参与者接收到Rollback请求后，开始执行事务rollback操作，执行完回滚事务之后，释放整个事务执行期间占用的资源。
   
   反馈事务回滚结果。
   
   参与者在完成事务回滚之后，向协调者发送Ack消息。
   
   中断事务。
   协调者接收到所有参与者反馈的Ack消息后，完成事务中断。
   
   2pc算法的缺点
   1. 单点问题
   
   ​   在整个过程中，只有一个协调者，如果在执行过程中协调者宕机或发生异常，则整个节点集群，会发生故障
   
   2. 同步阻塞问题
   
      在整个事务提交过程中，协调者需要等待所有的参与者的ACK消息，才能执行下一步操作，发生同步阻塞。
      
   Zookeeper的核心是原子广播机制，这个机制保证了各个server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式和广播模式。
   
   (1) 恢复模式
   
   当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数server完成了和leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和server具有相同的系统状态。
   
   (2) 广播模式
   
   一旦Leader已经和多数的Follower进行了状态同步后，他就可以开始广播消息了，即进入广播状态。这时候当一个Server加入ZooKeeper服务中，它会在恢复模式下启动，发现Leader，并和Leader进行状态同步。待到同步结束，它也参与消息广播。ZooKeeper服务一直维持在Broadcast状态，直到Leader崩溃了或者Leader失去了大部分的Followers支持。
   
   Broadcast模式极其类似于分布式事务中的2pc（two-phrase commit 两阶段提交）：即Leader提起一个决议，由Followers进行投票，Leader对投票结果进行计算决定是否通过该决议，如果通过执行该决议（事务），否则什么也不做。
   
   在广播模式ZooKeeper Server会接受Client请求，所有的写请求都被转发给领导者，再由领导者将更新广播给跟随者。当半数以上的跟随者已经将修改持久化之后，领导者才会提交这个更新，然后客户端才会收到一个更新成功的响应。这个用来达成共识的协议被设计成具有原子性，因此每个修改要么成功要么失败。   

8. 大数据量优化 读写分离，缓存，nosql,es搜索
9. 微服务降级，轮询策略，加权轮询设计
10. 接口缓存设计，key在10亿级
11. zk临时节点，永久节点的使用场景
12. 设计高效配置，能够动态更新
13. 设计当前一小时点击量top10新闻
    1. 对每篇新闻摘要计算一个hashcode，并建立摘要与hashcode的关联关系，使用map存储，以hashCode为key，新闻摘要为值
    2. 按每小时一个文件的方式记录下被点击的摘要的hashCode
    3. 当一个小时结果后，上一个小时的文件被关闭，开始计算上一个小时的点击top10
    4. 将hashcode分片到多个文件中，通过对hashCode取模运算，即可将相同的hashCode分片到相同的文件中
    5. 针对每个文件取top10的hashCode，使用Map<hashCode,int>的方式，统计出所有的摘要点击次数，然后再使用小顶堆（大小为10）计算top10,
    6. 再针对所有分片计算一个总的top10,最后合并的逻辑也是使用小顶堆，计算top10
    7. 如果仅展示前一个小时的top10,计算结束
    8. 如果需要展示全天，需要与上一次的计算按hashCode进行合并，然后在这合并的数据中取top10
    9. 在展示时，将计算得到的top10的hashcode，转化为新闻摘要显示即可
14. 1亿个数，内存放不下，文件中，乱序，求，top
    解决TOP-K问题常用的两种方式:
    1. 堆
       维护K个数据的堆,之后依次使用数据来与堆顶元素比较,要么丢弃,要么替换掉堆顶元素,之后调整堆. 时间复杂度为:O(nlogK).
    2. 快速选择算法(类快速排序)
       对数据进行分隔(使用快排思想):
       
       若切分后的左子数组的长度 > k，则前k大元素必出现在左子数组中；
       若切分后的左子数组的长度 = k，则前k大元素为左子数组.
       若切分后的左子树组的长度 s < k, 则左子数组为前s大元素,在右子数组中寻找前k-s大元素.
       时间复杂度为:O(nlogK).
    
15. 实现缓存读取的伪代码
16. springcloud服务降级的实现，以及springcloud和dubbo通信方式的不同，dubbo常用配置参数和通信框架
17. Pid到服务之间如何映射
18. 缓存如何实现事务
    Redis 允许将 Lua 脚本传到 Redis 服务器中执行, 脚本内可以调用大部分 Redis 命令, 且 Redis 保证脚本的原子性
    redis单线程加Lua可以保证原子性
    Lua 嵌入 Redis 优势: 
    减少网络开销: 不使用 Lua 的代码需要向 Redis 发送多次请求, 而脚本只需一次即可, 减少网络传输;
    原子操作: Redis 将整个脚本作为一个原子执行, 无需担心并发, 也就无需事务;
    复用: 脚本会永久保存 Redis 中, 其他客户端可继续使用.
    
    事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发送来的命令请求所打断。
    事务是一个原子操作：事务中的命令要么全部被执行，要么全部都不执行。
    MULTI 开启事务，总是返回OK，EXEC 提交事务，DISCARD放弃事务（放弃提交执行），WATCH监控
    QUEUED是将命令加入执行的队列
    首先使用MULTI命令告诉Redis：“下面我发给你的命令属于同一个事务，你先不要执行，而是把它们暂时存起来。”Redis回答：“OK。”
    而后我们发送了两个SADD命令来实现关注和被关注操作，可以看到Redis遵守了承诺，没有执行这些命令，而是 返回QUEUED表示这两条命令已经进入等待执行的事务队列 中了。
    我们 使用EXEC命令告诉Redis将等待执行的事务队列中的所有命令（即刚才所有返回QUEUED的命令）按照发送顺序依次执行。EXEC命令的返回值就是这些命令的返回值组成的列表，返回值顺序和命令的顺序相同。
    Redis保证一个事务中的所有命令要么都执行，要么都不执行。如果在发送EXEC命令前客户端断线了，则Redis会清空事务队列，事务中的所有命令都不会执行。而 一旦客户端发送了EXEC命令，所有的命令就都会被执行，即使此后客户端断线也没关系，因为Redis中已经记录了所有要执行的命令。
    WATCH命令可以监控一个或多个键，一旦其中有一个键被修改（或删除），之后的事务就不会执行。 监控一直持续到EXEC命令（事务中的命令是在EXEC之后才执行的，所以在MULTI命令后可以修改WATCH监控的键值）
    执行EXEC命令后会取消对所有键的监控 ，如果不想执行事务中的命令也可以使用 UNWATCH 命令来取消监控
19. 注册中心，健壮性设计，服务降级
20. 如何定位cpu飙升的实例
    jstack是jdk自带的线程堆栈分析工具，使用该命令可以查看或导出 Java 应用程序中线程堆栈信息。

    可能碰到的问题：CPU 100%，以及Full GC次数过多的问题。
    1. 代码中有比较耗CPU的操作，导致CPU过高，系统运行缓慢；相对来说，这是出现频率最高的两种线上问题，而且它们会直接导致系统不可用。
    2. 代码中某个位置读取数据量较大，导致系统内存耗尽，从而导致Full GC次数过多，系统缓慢；
    另外有几种情况也会导致某个功能运行缓慢，但是不至于导致系统不可用：
    3. 代码某个位置有阻塞性的操作，导致该功能调用整体比较耗时，但出现是比较随机的；
    4. 某个线程由于某种原因而进入WAITING状态，此时该功能整体不可用，但是无法复现；
    5. 由于锁使用不当，导致多个线程进入死锁状态，从而导致系统整体比较缓慢。
    
    解决：
    1. Full GC次数过多
       表现的现象：
       1. 线上多个线程的CPU都超过了100%，通过jstack命令可以看到这些线程主要是垃圾回收线程
       2. 通过jstat命令监控GC情况，可以看到Full GC次数非常多，并且次数在不断增加。
       
       处理：
       1. 使用top命令查看系统CPU的占用情况
       2. 有一个Java程序此时CPU占用量达到了98.8%，此时我们可以复制该进程id 9，并且使用如下命令查看呢该进程的各个线程运行情况 top -Hp 9
       3. jstack命令查看线程id为 10的线程为什么耗费CPU最高。
       4. 在jsatck命令展示的结果中，线程id都转换成了十六进制形 printf "%x\n" 10a
       5. 这里打印结果说明该线程在jstack中的展现形式为 0xa,这里的VM Thread一行的最后显示 nid=0xa，这里nid的意思就是操作系统线程id的意思。而VM Thread指的就是垃圾回收的线程。
       6. 基本上可以确定，当前系统缓慢的原因主要是垃圾回收过于频繁，导致GC停顿时间较长。我们通过如下命令可以查看GC的情况
          jstat -gcutil 2388 3000 6  每隔3秒打印一次pid为2388的堆内存的使用情况，共打印6次。
       7. 确认了内存溢出，但是如何查看你是哪些对象导致的内存溢出呢，这个可以dump出内存日志，然后通过eclipse的mat工具进行查看
       8. 也就是说，其还不足以导致大量的Full GC，此时我们需要考虑另外一种情况，就是代码或者第三方依赖的包中有显示的 System.gc()调用。   
       
       总结来说，对于Full GC次数过多，主要有以下两种原因：
       1. 代码中一次获取了大量的对象，导致内存溢出，此时可以通过eclipse的mat工具查看内存中有哪些对象比较多；
       2. 内存占用不高，但是Full GC次数还是比较多，此时可能是显示的 System.gc()调用导致GC次数过多，这可以通过添加 -XX:+DisableExplicitGC来禁用JVM对显示GC的响应。
    
    2. CPU过高
       区分导致CPU过高的原因具体是Full GC次数过多还是代码中有比较耗时的计算了。
   
       如果是Full GC次数过多，那么通过 jstack得到的线程信息会是类似于VM Thread之类的线程，而如果是代码中有比较耗时的计算，那么我们得到的就是一个线程的具体堆栈信息。   
    3. 不定期出现的接口耗时现象
       一般来说，其消耗的CPU不多，而且占用的内存也不高，也就是说，我们通过上述两种方式进行排查是无法解决这种问题的。
       首先找到该接口，通过压测工具不断加大访问力度，如果说该接口中有某个位置是比较耗时的，由于我们的访问的频率非常高，那么大多数的线程最终都将阻塞于该阻塞点
       
       这样通过多个线程具有相同的堆栈日志，我们基本上就可以定位到该接口中比较耗时的代码的位置。
    4. 某个线程进入WAITING状态
    
       场景：
       具体的场景是，在使用CountDownLatch时，由于需要每一个并行的任务都执行完成之后才会唤醒主线程往下执行。
       
       当时我们是通过CountDownLatch控制多个线程连接并导出用户的gmail邮箱数据，这其中有一个线程连接上了用户邮箱，但是连接被服务器挂起了，导致该线程一直在等待服务器的响应。最终导致我们的主线程和其余几个线程都处于WAITING状态。
       
       查看过jstack日志的读者应该都知道，正常情况下，线上大多数线程都是处于 TIMED_WAITING状态，而我们这里出问题的线程所处的状态与其是一模一样的，这就非常容易混淆我们的判断。   
       
       解决：
       1. 通过grep在jstack日志中找出所有的处于 TIMED_WAITING状态的线程，将其导出到某个文件中，如a1.log
       2. 等待一段时间之后，比如10s，再次对jstack日志进行grep，将其导出到另一个文件，如a2.log
       3. 重复步骤2，待导出3~4个文件之后，我们对导出的文件进行对比，找出其中在这几个文件中一直都存在的用户线程，这个线程基本上就可以确认是包含了处于等待状态有问题的线程。因为正常的请求线程是不会在20~30s之后还是处于等待状态的。
       4. 经过排查得到这些线程之后，我们可以继续对其堆栈信息进行排查，如果该线程本身就应该处于等待状态，比如用户创建的线程池中处于空闲状态的线程，那么这种线程的堆栈信息中是不会包含用户自定义的类的。这些都可以排除掉，而剩下的线程基本上就可以确认是我们要找的有问题的线程。通过其堆栈信息，我们就可以得出具体是在哪个位置的代码导致该线程处于等待状态了。
       
       我们在判断是否为用户线程时，可以通过线程最前面的线程名来判断，因为一般的框架的线程命名都是非常规范的，我们通过线程名就可以直接判断得出该线程是某些框架中的线程，这种线程基本上可以排除掉。
       
    5. 死锁
       对于死锁，这种情况基本上很容易发现，因为 jstack可以帮助我们检查死锁，并且在日志中打印具体的死锁线程信息。
       在jstack日志的底部，其直接帮我们分析了日志中存在哪些死锁，以及每个死锁的线程堆栈信息。   
          
21. 微服务的轮询测试是在 server端还是client端，还是注册中心 
    client端

22. 设计短连接
23. 内存碎片用compact,分配用buddy算法
    外部碎片避免——伙伴系统算法
    内部碎片避免——slab 算法
    
    外部碎片指的是还没有被分配出去（不属于任何进程），但由于太小了无法分配给申请内存空间的新进程的内存空闲区域3) 组织结构
    
    Linux kernel组织管理物理内存的方式是buddy system（伙伴系统）
    1 低内存时整合碎片
    从buddy申请内存页，如果找不到合适的页，则会进行两步调整内存的工作，compact和reclaim。前者是为了整合碎片，以得到更大的连续内存；后者是回收不一定必须占用内存的缓冲内存。
    
    开发一种特有的分配技术来记录下来空闲内存的情况，从而解决内存碎片问题。
    1. inux kernel 通过把整个物理内存划分成以一个个page进行管理，管理器就是伙伴系统，它的最小分配单元就是page。但是对于小于page的内存分配，如果直接分配一个page，是一个很大的浪费。linux kernel 通过slab来实现对小于page大小的内存分配。slab把page按2的m次幂进行划分一个个字节块，当kmalloc申请内存时，通过slab管理器返回需要满足申请大小的最小空闲内存块。
    2. slub主要是针对slab的对象管理数据的优化版本，相比于slab，slub提供更小的管理成本开销。而且slub对多核系统的支持也更加友好。细节这里就不展开讲。
    3. 所以kernel的内存管理是个2层分层系统，从下往上依次为：
    4. 第一层为全部物理内存：其管理器为伙伴系统，最小管理单位为page；
    5. 第二层为slab page：其管理器为slab/slub，最小管理单位为2的m次幂的字节块；
    
    伙伴系统:
    Linux采用著名的伙伴系统(buddy system)算法来解决外碎片问题。把所有的空闲页框分组为11个块链表，每个链表分别包含大小为1,2,4,8,16,32,64,128,256,512,1024个连续的页框，对1024个页框的最大请求对应着4MB大小的连续RAM（每页大小为4KB），每个块的第一个页框的物理地址是该块大小的整数倍，例如，大小为16个页框的块，其起始地址是16*2^12的倍数。
    我们通过一个例子来说明伙伴算法的工作原理，假设现在要请求一个256个页框的块（1MB），算法步骤如下：
    • 在256个页框的链表中检查是否有一个空闲快，如果没有，查找下一个更大的块，如果有，请求满足。
    • 在512个页框的链表中检查是否有一个空闲块，如果有，把512个页框的空闲块分为两份，第一份用于满足请求，第二份链接到256个页框的链表中。如果没有空闲块，继续寻找下一个更大的块。
    
    以上过程的逆过程，就是页框块的释放过程，也是该算法名字的由来，内核试图把大小为B的一对空闲伙伴块合并为一个2B的单独块，满足以下条件的两个块称之为伙伴：
    • 两个块具有相同的大小
    • 他们的物理地址是连续的
    第一块的第一个页框的物理地址是2 * B * 2^12
    该算法是递归的，如果它成功合并了B，就会试图去合并2B，以再次试图形成更大的块。

24. 调试思路
