1. 并发(Concurrency)和并行(Parallelism)
   
   并发和并行是两个非常容易被混淆的概念。它们都可以表示两个或者多个任务一起执行，但是偏重点有些不同。
   + 并发偏重于多个任务交替执行，而多个任务之间有可能还是串行的。
   + 而并行是真正意义上的“同时执行”。
   
   多线程在单核CPU的话是顺序执行，也就是交替运行（并发）。多核CPU的话，因为每个CPU有自己的运算器，所以在多个CPU中可以同时运行（并行）。
   
2. 高并发
   
   高并发（High Concurrency）是互联网分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计保证系统能够同时并行处理很多请求。
   
   高并发相关常用的一些指标有响应时间（Response Time），吞吐量（Throughput），每秒查询率QPS（Query Per Second），并发用户数等。
   
3. 临界区
   
   临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用。但是每一次，只能有一个线程使用它，一旦临界区资源被占用，其他线程要想使用这个资源，就必须等待。在并行程序中，临界区资源是保护的对象。

4. 使用多线程常见的三种方式
   
   + 继承Thread类    
   + 实现Runnable接口 
   + 使用线程池
   
5. 线程常用方法
   
   + currentThread() 返回对当前正在执行的线程对象的引用。
   + getId() 返回此线程的标识符
   + getName() 返回此线程的名称
   + getPriority() 返回此线程的优先级
   + isAlive() 测试这个线程是否还处于活动状态。什么是活动状态呢？活动状态就是线程已经启动且尚未终止。线程处于正在运行或准备运行的状态。
   + sleep(long millis) 使当前正在执行的线程以指定的毫秒数“休眠”（暂时停止执行），具体取决于系统定时器和调度程序的精度和准确性。
   + interrupt() 中断这个线程。
   + interrupted() 测试当前线程是否已经是中断状态，执行后具有将状态标志清除为false的功能
   + isInterrupted(）测试线程Thread对相关是否已经是中断状态，但部清楚状态标志
   + setName(String name) 将此线程的名称更改为等于参数 name 。
   + isDaemon() 测试这个线程是否是守护线程。
   + setDaemon(boolean on) 将此线程标记为 daemon线程或用户线程。
   + join() 在很多情况下，主线程生成并起动了子线程，如果子线程里要进行大量的耗时的运算，主线程往往将于子线程之前结束，但是如果主线程处理完其他的事务后，需要用到子线程的处理结果，也就是 主线程需要等待子线程执行完成之后再结束，这个时候就要用到join()方法了。
     join()的作用是：“等待该线程终止”，这里需要理解的就是该线程是指的主线程等待子线程的终止。也就是在子线程调用了join()方法后面的代码，只有等到子线程结束了才能执行
   + yield() yield()方法的作用是放弃当前的CPU资源，将它让给其他的任务去占用CPU时间。注意：放弃的时间不确定，可能一会就会重新获得CPU时间片。
   + setPriority(int newPriority) 更改此线程的优先级

6. 线程的状态
  
   + image/ThreadStatus1.png
   + image/ThreadStatus2.png
   
   1. 新建(new)：新创建了一个线程对象。 
   2. 可运行(runnable)：线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位于可运行线程池中，等待被线程调度选中，获 取cpu的使用权。 
   3. 运行(running)：可运行状态(runnable)的线程获得了cpu时间片（timeslice），执行程序代码。 
   4. 阻塞(block)：阻塞状态是指线程因为某种原因放弃了cpu使用权，也即让出了cpu timeslice，暂时停止运行。直到线程进入可运行(runnable)状态，才有 机会再次获得cpu timeslice转到运行(running)状态。阻塞的情况分三种：
   
      + **等待阻塞**：运行(running)的线程执行o.wait()方法，JVM会把该线程放 入等待队列(waitting queue)中。
      + **同步阻塞**：运行(running)的线程在获取对象的同步锁时，若该同步锁 被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。
      + **其他阻塞**: 运行(running)的线程执行Thread.sleep(long ms)或t.join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入可运行(runnable)状态。
     
   5. 死亡(dead)：线程run()、main()方法执行结束，或者因异常退出了run()方法，则该线程结束生命周期。死亡的线程不可再次复生

7. 线程终止 return
8. 多线程分类
   + 用户线程：运行在前台，执行具体的任务，如程序的主线程、连接网络的子线程等都是用户线程
   + 守护线程：运行在后台，为其他前台线程服务.也可以说守护线程是JVM中非守护线程的 “佣人”。
   
   特点：一旦所有用户线程都结束运行，守护线程会随JVM一起结束工作
   
   应用：数据库连接池中的检测线程，JVM虚拟机启动后的检测线程
   
   最常见的守护线程：垃圾回收线程

---------

#### synchronized
1. 简介

   Java并发编程这个领域中synchronized关键字一直都是元老级的角色，很久之前很多人都会称它为“重量级锁”。但是，在JavaSE 1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后变得在某些情况下并不是那么重了    

2. 变量安全性
   
   “非线程安全”问题存在于“实例变量”中，如果是方法内部的私有变量，则不存在“非线程安全”问题，所得结果也就是“线程安全”的了。
   
   如果两个线程同时操作对象中的实例变量，则会出现“非线程安全”，解决办法就是在方法前加上synchronized关键字即可。
   
3. synchronized取得的锁都是对象锁，而不是把一段代码或方法当做锁。 哪个线程先执行带synchronized关键字的方法，则哪个线程就持有该方法所属对象的锁Lock，那么其他线程只能呈等待状态，前提是多个线程访问的是同一个对象。  
  
4. 可重入锁：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。可重入锁也支持在父子类继承的环境中，说明当存在父子类继承关系时，子类是完全可以通过“可重入锁”调用父类的同步方法。
    
5. 同步不具有继承性。如果父类有一个带synchronized关键字的方法，子类继承并重写了这个方法。 但是同步不能继承，所以还是需要在子类方法中添加synchronized关键字。       
   
6. synchronized同步块  
   
   当一个线程访问一个对象的synchronized同步代码块时，另一个线程任然可以访问该对象非synchronized同步代码块。 
   
   时间虽然缩短了，但是大家考虑一下synchronized代码块真的是同步的吗？它真的持有当前调用对象的锁吗？
   
   是的。不在synchronized代码块中就异步执行，在synchronized代码块中就是同步执行。
   
   当一个对象访问synchronized(this)代码块时，其他线程对同一个对象中所有其他synchronized(this)代码块代码块的访问将被阻塞，这说明synchronized(this)代码块使用的“对象监视器”是一个。 
   也就是说和synchronized方法一样，synchronized(this)代码块也是锁定当前对象的。
   
   另外通过上面的学习我们可以得出两个结论。
   
   + 其他线程执行对象中synchronized同步方法和synchronized(this)代码块时呈现同步效果;
   + 如果两个线程使用了同一个“对象监视器”,运行结果同步，否则不同步.

7. 静态同步synchronized方法与synchronized(class)代码块

   synchronized关键字加到static静态方法和synchronized(class)代码块上都是是给Class类上锁，Class锁对对象的所有实例起作用，而synchronized关键字加到非static静态方法上是给对象上锁。   
  
   注意：
   
   字符串常量池中的字符串只存在一份！ 即执行完第一行代码后，常量池中已存在 “a”，那么s2不会在常量池中申请新的空间，而是直接把已存在的字符串内存地址返回给s2。
   
   因为数据类型String的常量池属性，所以synchronized(string)在使用时某些情况下会出现一些问题，比如两个线程运行 
   synchronized(“abc”)｛ 
   ｝和 
   synchronized(“abc”)｛ 
   ｝修饰的方法时，这两个线程就会持有相同的锁，导致某一时刻只有一个线程能运行。所以尽量不要使用synchronized(string)而使用synchronized(object)

   String.intern()是一个Native方法，底层调用C++的 StringTable::intern方法实现。当通过语句str.intern()调用intern()方法后，JVM 就会在当前类的常量池中查找是否存在与str等值的String，若存在则直接返回常量池中相应Strnig的引用；若不存在，则会在常量池中创建一个等值的String，然后返回这个String在常量池中的引用。因此，只要是等值的String对象，使用intern()方法返回的都是常量池中同一个String引用，所以，这些等值的String对象通过intern()后使用==是可以匹配的。由此就可以理解上面代码中------intern------部分的结果了。因为str1、str5和str6是三个等值的String，所以通过intern()方法，他们均会指向常量池中的同一个String引用，因此str1.intern() == str5.intern() == str6.intern()均为true。

#### volatile
1. 简介
   volatile两大作用
   1、保证内存可见性
   
   2、防止指令重排
      指令重排序是JVM为了优化指令，提高程序运行效率，在不影响单线程程序执行结果的前提下，尽可能地提高并行度。编译器、处理器也遵循这样一个目标。注意是单线程。多线程的情况下指令重排序就会给程序员带来问题。
   
   在 JDK1.2 之前，Java的内存模型实现总是从主存（即共享内存）读取变量，是不需要进行特别的注意的。而在当前的 Java 内存模型下，线程可以把变量保存本地内存（比如机器的寄存器）中，而不是直接在主存中进行读写。这就可能造成一个线程在主存中修改了一个变量的值，而另外一个线程还继续使用它在寄存器中的变量值的拷贝，造成数据的不一致。
   要解决这个问题，就需要把变量声明为 volatile。

2. volatile关键字的可见性
   
   volatile 修饰的成员变量在每次被线程访问时，都强迫从主存（共享内存）中重读该成员变量的值。而且，当成员变量发生变化时，强迫线程将变化值回写到主存（共享内存）。
   这样在任何时刻，两个不同的线程总是看到某个成员变量的同一个值，这样也就保证了同步数据的可见性。
   
   JVM会尽力保证内存的可见性，即便这个变量没有加同步关键字。换句话说，只要CPU有时间，JVM会尽力去保证变量值的更新。这种与volatile关键字的不同在于，volatile关键字会强制的保证线程的可见性。
   而不加这个关键字，JVM也会尽力去保证可见性，但是如果CPU一直有其他的事情在处理，它也没办法。最开始的代码，一直处于死循环中，CPU处于一直占用的状态，这个时候CPU没有时间，JVM也不能强制要求CPU分点时间去取最新的变量值。而加了输出或者sleep语句之后，CPU就有可能有时间去保证内存的可见性，于是while循环可以被终止。
   
3. volatile关键字能保证原子性吗
   
   要保证数据的原子性还是要使用synchronized关键字。

4. synchronized关键字和volatile关键字比较
 
   + volatile关键字是线程同步的轻量级实现，所以volatile性能肯定比synchronized关键字要好。但是volatile关键字只能用于变量而synchronized关键字可以修饰方法以及代码块。
     synchronized关键字在JavaSE1.6之后进行了主要包括为了减少获得锁和释放锁带来的性能消耗而引入的偏向锁和轻量级锁以及其它各种优化之后执行效率有了显著提升，实际开发中使用synchronized关键字还是更多一些。
   + 多线程访问volatile关键字不会发生阻塞，而synchronized关键字可能会发生阻塞
   + volatile关键字能保证数据的可见性，但不能保证数据的原子性。synchronized关键字两者都能保证。
   + volatile关键字用于解决变量在多个线程之间的可见性，而synchronized关键字解决的是多个线程之间访问资源的同步性。

#### 等待/通知（wait/notify）机制   
1. 简介

   当两个线程之间存在生产和消费者关系，也就是说第一个线程（生产者）做相应的操作然后第二个线程（消费者）感知到了变化又进行相应的操作。比如像下面的whie语句一样，假设这个value值就是第一个线程操作的结果，doSomething()是第二个线程要做的事，当满足条件value=desire后才执行doSomething()。
   
   但是这里有个问题就是：第二个语句不停过通过轮询机制来检测判断条件是否成立。如果轮询时间的间隔太小会浪费CPU资源，轮询时间的间隔太大，就可能取不到自己想要的数据。所以这里就需要我们今天讲到的等待/通知（wait/notify）机制来解决这两个矛盾。

2. 解释

   等待/通知机制，是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B调用了对象O的notify()/notifyAll()方法，线程A收到通知后退出等待队列，进入可运行状态，进而执行后续操作。
   上诉两个线程通过对象O来完成交互，而对象上的wait()方法和notify()/notifyAll()方法的关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作。

3. 常用方法
   
   + notify() 随机唤醒等待队列中等待同一共享资源的 “一个线程”，并使该线程退出等待队列，进入可运行状态，也就是notify()方法仅通知“一个线程
   + notifyAll() 使所有正在等待队列中等待同一共享资源的 “全部线程” 退出等待队列，进入可运行状态。此时，优先级最高的那个线程最先执行，但也有可能是随机执行，这取决于JVM虚拟机的实现
   + wait() 使调用该方法的线程释放共享资源锁，然后从运行状态退出，进入等待队列，直到被再次唤醒
   + wait(long) 超时等待一段时间，这里的参数时间是毫秒，也就是等待长达n毫秒，如果没有通知就超时返回
   + wait(long，int) 对于超时时间更细力度的控制，可以达到纳秒
   
   补充：
   
   synchronized关键字可以将任何一个Object对象作为同步对象来看待，而Java为每个Object都实现了等待/通知（wait/notify）机制的相关方法，它们必须用在synchronized关键字同步的Object的临界区内。
   通过调用wait()方法可以使处于临界区内的线程进入等待状态，同时释放被同步对象的锁。而notify()方法可以唤醒一个因调用wait操作而处于阻塞状态中的线程，使其进入就绪状态。
   被重新唤醒的线程会视图重新获得临界区的控制权也就是锁，并继续执行wait方法之后的代码。如果发出notify操作时没有处于阻塞状态中的线程，那么该命令会被忽略。

4. notify()锁不释放      
   
   当方法wait()被执行后，锁自动被释放，但执行完notify()方法后，锁不会自动释放。必须执行完notify()方法所在的synchronized代码块后才释放。

5. 当interrupt方法遇到wait方法
  
   当线程呈wait状态时，对线程对象调用interrupt方法会出现InterrupedException异常。   
     
#### 线程间相互通信（synchronized关键字、volatile关键字以及等待/通知（wait/notify）机制、管道输入/输出流、Thread.join()的使用、ThreadLocal）

1. 管道输入/输出流
   
   管道输入/输出流和普通文件的输入/输出流或者网络输入、输出流不同之处在于管道输入/输出流主要用于线程之间的数据传输，而且传输的媒介为内存。     
   
   管道输入/输出流主要包括下列两类的实现：
   
   + 面向字节： PipedOutputStream、 PipedInputStream
   + 面向字符: PipedWriter、 PipedReader
   
   定义了两个方法writeMethod和readMethod,前者用于写字节/字符（取决于你用的是PipedOuputStream还是PipedWriter），后者用于读取字节/字符（取决于你用的是PipedInputStream还是PipedReader）.我们定义了两个线程threadRead和threadWrite ，threadRead线程运行readMethod方法，threadWrite运行writeMethod方法。然后 通过outputStream.connect(inputStream)或inputStream.connect(outputStream)使两个管道流产生链接，这样就可以将数据进行输入与输出了。

2. Thread.join()的使用
    
   在很多情况下，主线程生成并起动了子线程，如果子线程里要进行大量的耗时的运算，主线程往往将于子线程之前结束，但是如果主线程处理完其他的事务后，需要用到子线程的处理结果，也就是主线程需要等待子线程执行完成之后再结束，这个时候就要用到join()方法了。另外，一个线程需要等待另一个线程也需要用到join()方法。
   
   Thread类除了提供join()方法之外，还提供了join(long millis)、join(long millis, int nanos)两个具有超时特性的方法。这两个超时方法表示，如果线程thread在指定的超时时间没有终止，那么将会从该超时方法中返回。

3. ThreadLocal的使用 

   变量值的共享可以使用public static变量的形式，所有线程都使用一个public static变量。如果想实现每一个线程都有自己的共享变量该如何解决呢？JDK中提供的ThreadLocal类正是为了解决这样的问题。ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。
    
   ThreadLocal类相关方法：
   + get() 返回当前线程的此线程局部变量的副本中的值。
   + set(T value) 将当前线程的此线程局部变量的副本设置为指定的值
   + remove() 删除此线程局部变量的当前线程的值。
   + initialValue() 返回此线程局部变量的当前线程的“初始值”
   
   ThreadLocal类固然很好，但是子线程并不能取到父线程的ThreadLocal类的变量，InheritableThreadLocal类就是解决这个问题的。
   在使用InheritableThreadLocal类需要注意的一点是：如果子线程在取得值的同时，主线程将InheritableThreadLocal中的值进行更改，那么子线程取到的还是旧值。
   
#### Lock锁的使用
1. 简介
   锁是用于通过多个线程控制对共享资源的访问的工具。通常，锁提供对共享资源的独占访问：一次只能有一个线程可以获取锁，并且对共享资源的所有访问都要求首先获取锁。 但是，一些锁可能允许并发访问共享资源，如ReadWriteLock的读写锁。   
   在Lock接口出现之前，Java程序是靠synchronized关键字实现锁功能的。JDK1.5之后并发包中新增了Lock接口以及相关实现类来实现锁功能。
   ```
      Lock lock=new ReentrantLock()；
      lock.lock();
       try{
        }finally{
        lock.unlock();
        }
   ```
   因为Lock是接口所以使用时要结合它的实现类，另外在finall语句块中释放锁的目的是保证获取到锁之后，最终能够被释放。
   注意： 最好不要把获取锁的过程写在try语句块中，因为如果在获取锁时发生了异常，异常抛出的同时也会导致锁无法被释放。
2. 接口实现类
   
   Lock接口的实现类： 
   ReentrantLock ， ReentrantReadWriteLock.ReadLock ， ReentrantReadWriteLock.WriteLock

3. 基本方法
   
   + void lock() 获得锁。如果锁不可用，则当前线程将被禁用以进行线程调度，并处于休眠状态，直到获取锁。
   + void lockInterruptibly() 获取锁，如果可用并立即返回。如果锁不可用，那么当前线程将被禁用以进行线程调度，并且处于休眠状态，和lock()方法不同的是在锁的获取中可以中断当前线程（相应中断）。
   + Condition newCondition() 获取等待通知组件，该组件和当前的锁绑定，当前线程只有获得了锁，才能调用该组件的wait()方法，而调用后，当前线程将释放锁。
   + boolean tryLock() 只有在调用时才可以获得锁。如果可用，则获取锁定，并立即返回值为true；如果锁不可用，则此方法将立即返回值为false 。
   + boolean tryLock(long time, TimeUnit unit) 超时获取锁，当前线程在一下三种情况下会返回： 1. 当前线程在超时时间内获得了锁；2.当前线程在超时时间内被中断；3.超时时间结束，返回false.
   + void unlock() 释放锁

4. ReentrantLock
   
   构造方法：
   + ReentrantLock() ReentrantLock()
   + ReentrantLock(boolean fair) 创建一个特定锁类型（公平锁/非公平锁）的ReentrantLock的实例   
   
   常见方法：
   
   + int getHoldCount()	查询当前线程保持此锁定的个数，也就是调用lock()方法的次数。
   + protected Thread getOwner()	返回当前拥有此锁的线程，如果不拥有，则返回 null
   + protected Collection getQueuedThreads()	返回包含可能正在等待获取此锁的线程的集合
   + int getQueueLength()	返回等待获取此锁的线程数的估计。
   + protected Collection getWaitingThreads(Condition condition)	返回包含可能在与此锁相关联的给定条件下等待的线程的集合。
   + int getWaitQueueLength(Condition condition)	返回与此锁相关联的给定条件等待的线程数的估计。
   + boolean hasQueuedThread(Thread thread)	查询给定线程是否等待获取此锁。
   + boolean hasQueuedThreads()	查询是否有线程正在等待获取此锁。
   + boolean hasWaiters(Condition condition)	查询任何线程是否等待与此锁相关联的给定条件
   + boolean isFair()	如果此锁的公平设置为true，则返回 true 。
   + boolean isHeldByCurrentThread()	查询此锁是否由当前线程持有。
   + boolean isLocked()	查询此锁是否由任何线程持有。
 
5. Condition接口
    
    private Lock lock = new ReentrantLock();
    
    public Condition condition = lock.newCondition();
    
    synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。
    
    在使用notify/notifyAll()方法进行通知时，被通知的线程是有JVM选择的，使用ReentrantLock类结合Condition实例可以实现“选择性通知”，这个功能非常重要，而且是Condition接口默认提供的。
    
    而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程
    
    常见方法：
    
    + void await()	相当于Object类的wait方法
    + boolean await(long time, TimeUnit unit)	相当于Object类的wait(long timeout)方法
    + signal()	相当于Object类的notify方法
    + signalAll()	相当于Object类的notifyAll方法
    
    在使用wait/notify实现等待通知机制的时候我们知道必须执行完notify()方法所在的synchronized代码块后才释放锁。在这里也差不多，必须执行完signal所在的try语句块之后才释放锁，condition.await()后的语句才能被执行。

6. 公平锁和非公平锁
   
   Lock锁分为：公平锁 和 非公平锁。公平锁表示线程获取锁的顺序是按照线程加锁的顺序来分配的，即先来先得的FIFO先进先出顺序。而非公平锁就是一种获取锁的抢占机制，是随机获取锁的，和公平锁不一样的就是先来的不一定先的到锁，这样可能造成某些线程一直拿不到锁，结果也就是不公平的了

7. ReentrantReadWriteLock
   
   简介：
   我们刚刚接触到的ReentrantLock（排他锁）具有完全互斥排他的效果，即同一时刻只允许一个线程访问，这样做虽然虽然保证了实例变量的线程安全性，但效率非常低下。ReadWriteLock接口的实现类-ReentrantReadWriteLock读写锁就是为了解决这个问题。
   
   读写锁维护了两个锁，一个是读操作相关的锁也成为共享锁，一个是写操作相关的锁 也称为排他锁。通过分离读锁和写锁，其并发性比一般排他锁有了很大提升。
   
   多个读锁之间不互斥，读锁与写锁互斥，写锁与写锁互斥（只要出现写操作的过程就是互斥的。）。在没有线程Thread进行写入操作时，进行读取操作的多个Thread都可以获取读锁，而进行写入操作的Thread只有在获取写锁后才能进行写入操作。即多个Thread可以同时进行读取操作，但是同一时刻只允许一个Thread进行写入操作。
   
   锁降级：遵循获取写锁、获取读锁再释放写锁的次序，写锁能够降级称为读锁
   
8. 并发的一些问题
   
   并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、上下文切换、死锁还有受限于硬件和软件的资源闲置问题。
   
   多线程就是几乎同时执行多个线程（一个处理器在某一个时间点上永远都只能是一个线程！即使这个处理器是多核的，除非有多个处理器才能实现多个线程同时运行）。CPU通过给每个线程分配CPU时间片来实现伪同时运行，因为CPU时间片一般很短很短，所以给人一种同时运行的感觉。
   
   上下文切换：当前任务在执行完CPU时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换会这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 
    
   减少上下文切换的方法：
   + 减少锁的使用。 因为多线程竞争锁时会引起上下文切换
   + 使用CAS算法。 这种算法也是为了减少锁的使用。CAS算法是一种无锁算法。
   + 减少线程的使用。人物很少的时候创建大量线程会导致大量线程都处于等待状态。
   + 使用协程。协程也可以说是微线程或者说是轻量级的线程，它占用的内存更少并且更灵活。可以使用Java实现的开源协程库：Quasar。Quasar官网：http://www.paralleluniverse.co/quasar/，。这个库实现了一种可以和Go语言中的Goroutine相对标的编程概念：Fiber。Fiber是一种真正的协程。

9. CAS算法
   
   CAS（比较与交换，Compare and swap） 是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程被阻塞的情况下实现变量的同步，所以也叫非阻塞同步（Non-blocking Synchronization）。实现非阻塞同步的方案称为“无锁编程算法”（ Non-blocking algorithm）。 
   
   CAS机制当中使用了3个基本操作数：内存地址V，旧的预期值A，要修改的新值B
   
   更新一个变量的时候，只有当变量的预期值A和内存地址V当中的实际值相同时，才会将内存地址V对应的值修改为B。不同则CAS自旋锁适用于锁使用者保持锁时间比较短的情况中，因为自旋锁使用者一般保持锁的时间很短，所以才选择自旋而不是睡眠。自旋锁是采用让当前线程不停地的在循环体内执行实现的，当循环的条件被其他线程改变时 才能进入临界区
   
   CAS存在的问题
   + ABA问题
     因为CAS在进行操作的时候，总是需要比较新的操作数和旧的操作数，如果相同则更新。但是如果新的操作数经过两次修改之后返回原来的值，那么久出现了ABA问题。
     1. 线程 1 从内存位置V中取出A。
     2. 线程 2 从位置V中取出A。
     3. 线程 2 进行了一些操作，将B写入位置V。
     4. 线程 2 将A再次写入位置V。
     5. 线程 1 进行CAS操作，发现位置V中仍然是A，操作成功。
     
     解决问题的方法就是增加一个版本号，不仅仅通过检查值得变化来确定是否更新。乐观锁每次在执行数据的修改操作时，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本号执行+1 操作，否则就执行失败。因为每次操作的版本号都会随之增加，所以不会出现 ABA 问题，因为版本号只会增加不会减少。

10. 死锁
    
    在操作系统中，死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。
    
    四种避免死锁的常见方法：
    + 避免一个线程同时获得多个锁
    + 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源
    + 尝试使用定时锁，使用lock.tryLock(timeout)来替代使用内部锁机制
    + 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况
    
11. 偏向锁、轻量级锁、重量级锁
    
    内置锁是JVM提供的最便捷的线程同步工具，在代码块或方法声明上添加synchronized关键字即可使用内置锁。 从简单的重量级锁，到逐渐膨胀的锁分配策略，使用了多种优化手段解决隐藏在内置锁下的基本问题。
   
    + 重量级锁：内置锁在Java中被抽象为监视器锁（monitor）。在JDK 1.6之前，监视器锁可以认为直接对应底层操作系统中的互斥量（mutex）。这种同步方式的成本非常高，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。因此，后来称这种锁为“重量级锁”。
    + 自旋锁：通过自旋锁，可以减少线程阻塞造成的线程切换（包括挂起线程和恢复线程）。如果锁的粒度小，那么锁的持有时间比较短，那么，对于竞争这些锁的而言，因为锁阻塞造成线程切换的时间与锁持有的时间相当，减少线程阻塞造成的线程切换，能得到较大的性能提升。
      1. 当前线程竞争锁失败时，打算阻塞自己
      2. 不直接阻塞自己，而是自旋（空等待，比如一个空的有限for循环）一会
      3. 在自旋的同时重新竞争锁
      4. 如果自旋结束前获得了锁，那么锁获取成功；否则，自旋结束后阻塞自己
     
      如果在自旋的时间内，锁就被旧owner释放了，那么当前线程就不需要阻塞自己（也不需要在未来锁释放时恢复），减少了一次线程切换。
      
    + 轻量级锁
      
      自旋锁的目标是降低线程切换的成本。如果锁竞争激烈，我们不得不依赖于重量级锁，让竞争失败的线程阻塞；如果完全没有实际的锁竞争，那么申请重量级锁都是浪费的。轻量级锁的目标是，减少无实际竞争情况下，使用重量级锁产生的性能消耗，包括系统调用引起的内核态与用户态切换、线程阻塞造成的线程切换等。
      顾名思义，轻量级锁是相对于重量级锁而言的。使用轻量级锁时，不需要申请互斥量，仅仅将Mark Word中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功，记录锁状态为轻量级锁；否则，说明已经有线程获得了轻量级锁，目前发生了锁竞争（不适合继续使用轻量级锁），接下来膨胀为重量级锁。
      
      Mark Word是对象头的一部分；每个线程都拥有自己的线程栈（虚拟机栈），记录线程和函数调用的基本信息。二者属于JVM的基础内容，此处不做介绍。
      
    + 偏向锁
      
      在没有实际竞争的情况下，还能够针对部分场景继续优化。如果不仅仅没有实际竞争，自始至终，使用锁的线程都只有一个，那么，维护轻量级锁都是浪费的。偏向锁的目标是，减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。轻量级锁每次申请、释放锁都至少需要一次CAS，但偏向锁只有初始化时需要一次CAS。
      
      “偏向”的意思是，偏向锁假定将来只有第一个申请锁的线程会使用锁（不会有任何线程再来申请锁），因此，只需要在Mark Word中CAS记录owner（本质上也是更新，但初始值为空），如果记录成功，则偏向锁获取成功，记录锁状态为偏向锁，以后当前线程等于owner就可以零成本的直接获得锁；否则，说明有其他线程竞争，膨胀为轻量级锁。
      
      偏向锁无法使用自旋锁优化，因为一旦有其他线程申请锁，就破坏了偏向锁的假定。 
      
    总结：
    
    偏向锁、轻量级锁、重量级锁适用于不同的并发场景：    
    + 偏向锁：无实际竞争，且将来只有第一个申请锁的线程会使用锁。
    + 轻量级锁：无实际竞争，多个线程交替使用锁；允许短时间的锁竞争。
    + 重量级锁：有实际竞争，且锁竞争时间长。
    
    另外，如果锁竞争时间短，可以使用自旋锁进一步优化轻量级锁、重量级锁的性能，减少线程切换。
    
    JDK1.6 对锁的实现引入了大量的优化，如偏向锁、轻量级锁、自旋锁、适应性自旋锁、锁消除、锁粗化等技术来减少锁操作的开销。
    
    锁主要存在四中状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。
    
    ①偏向锁
    
    引入偏向锁的目的和引入轻量级锁的目的很像，他们都是为了没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗。但是不同是：轻量级锁在无竞争的情况下使用 CAS 操作去代替使用互斥量。而偏向锁在无竞争的情况下会把整个同步都消除掉。
    
    偏向锁的“偏”就是偏心的偏，它的意思是会偏向于第一个获得它的线程，如果在接下来的执行中，该锁没有被其他线程获取，那么持有偏向锁的线程就不需要进行同步！关于偏向锁的原理可以查看《深入理解Java虚拟机：JVM高级特性与最佳实践》第二版的13章第三节锁优化。
    
    但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。
    
    ② 轻量级锁
    
    倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)。轻量级锁不是为了代替重量级锁，它的本意是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生的性能消耗，因为使用轻量级锁时，不需要申请互斥量。另外，轻量级锁的加锁和解锁都用到了CAS操作。关于轻量级锁的加锁和解锁的原理可以查看《深入理解Java虚拟机：JVM高级特性与最佳实践》第二版的13章第三节锁优化。
    
    轻量级锁能够提升程序同步性能的依据是“对于绝大部分锁，在整个同步周期内都是不存在竞争的”，这是一个经验数据。如果没有竞争，轻量级锁使用 CAS 操作避免了使用互斥操作的开销。但如果存在锁竞争，除了互斥量开销外，还会额外发生CAS操作，因此在有锁竞争的情况下，轻量级锁比传统的重量级锁更慢！如果锁竞争激烈，那么轻量级将很快膨胀为重量级锁！
    
    ③ 自旋锁和自适应自旋
    
    轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。
    
    互斥同步对性能最大的影响就是阻塞的实现，因为挂起线程/恢复线程的操作都需要转入内核态中完成（用户态转换到内核态会耗费时间）。
    
    一般线程持有锁的时间都不是太长，所以仅仅为了这一点时间去挂起线程/恢复线程是得不偿失的。 所以，虚拟机的开发团队就这样去考虑：“我们能不能让后面来的请求获取锁的线程等待一会而不被挂起呢？看看持有锁的线程是否很快就会释放锁”。为了让一个线程等待，我们只需要让线程执行一个忙循环（自旋），这项技术就叫做自旋。
    
    百度百科对自旋锁的解释：
    
    何谓自旋锁？它是为实现保护共享资源而提出一种锁机制。其实，自旋锁与互斥锁比较类似，它们都是为了解决对某项资源的互斥使用。无论是互斥锁，还是自旋锁，在任何时刻，最多只能有一个保持者，也就说，在任何时刻最多只能有一个执行单元获得锁。但是两者在调度机制上略有不同。对于互斥锁，如果资源已经被占用，资源申请者只能进入睡眠状态。但是自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是否该自旋锁的保持者已经释放了锁，"自旋"一词就是因此而得名。
    
    自旋锁在 JDK1.6 之前其实就已经引入了，不过是默认关闭的，需要通过--XX:+UseSpinning参数来开启。JDK1.6及1.6之后，就改为默认开启的了。需要注意的是：自旋等待不能完全替代阻塞，因为它还是要占用处理器时间。如果锁被占用的时间短，那么效果当然就很好了！反之，相反！自旋等待的时间必须要有限度。如果自旋超过了限定次数任然没有获得锁，就应该挂起线程。自旋次数的默认值是10次，用户可以修改--XX:PreBlockSpin来更改。
    
    另外,在 JDK1.6 中引入了自适应的自旋锁。自适应的自旋锁带来的改进就是：自旋的时间不在固定了，而是和前一次同一个锁上的自旋时间以及锁的拥有者的状态来决定，虚拟机变得越来越“聪明”了。
    
    ④ 锁消除
    
    锁消除理解起来很简单，它指的就是虚拟机即使编译器在运行时，如果检测到那些共享数据不可能存在竞争，那么就执行锁消除。锁消除可以节省毫无意义的请求锁的时间。
    
    ⑤ 锁粗化
    
    原则上，我们再编写代码的时候，总是推荐将同步快的作用范围限制得尽量小——只在共享数据的实际作用域才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁竞争，那等待线程也能尽快拿到锁。
    
    大部分情况下，上面的原则都是没有问题的，但是如果一系列的连续操作都对同一个对象反复加锁和解锁，那么会带来很多不必要的性能消耗。
  

12. JUC原子类4类
    
    + 基本类型 使用原子的方式更新基本类型
    
      AtomicInteger:整形原子类 AtomicLong:长整型原子类 AtomicBoolean :布尔型原子类
      
    + 数组类型
    
      使用原子的方式更新数组里的某个元素
      
      AtomicIntegerArray:整形数组原子类 AtomicLongArray:长整形数组原子类 AtomicReferenceArray :引用类型数组原子类
    
    + 引用类型
     
      AtomicReference:引用类型原子类 AtomicStampedRerence:原子更新引用类型里的字段原子类 AtomicMarkableReference :原子更新带有标记位的引用类型
      
    + 对象的属性修改类型 AtomicIntegerFieldUpdater:原子更新整形字段的更新器 AtomicLongFieldUpdater:原子更新长整形字段的更新器
      AtomicStampedReference :原子更新带有版本号的引用类型。该类将整数值与引用关联起来，可用于解决原 子的更新数据和数据的版本号，可以解决使用 CAS 进行原子更新时可能出现的 ABA 问题。

    AtomicInteger 线程安全原理简单分析：
    
    AtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。
    
    CAS的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法 是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个volatile变 量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。
    
13. 线程池
    
    ![线程池继承关系](http://my-blog-to-use.oss-cn-beijing.aliyuncs.com/18-4-16/90058574.jpg)
   
    好处：
    + 降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
    + 提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
    + 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。
    
    ThreadPoolExecutor 
    
    Executor框架：（三部分组成）
    
    1.任务：执行任务需要实现的Runnable接口或Callable接口。
    2.任务的执行：包括任务执行机制的核心接口Executor ，以及继承自Executor接口的ExecutorService接口。ScheduledThreadPoolExecutor和ThreadPoolExecutor这两个关键类实现了ExecutorService接口。
    3.异步计算的结果  Future接口以及Future接口的实现类FutureTask类。当我们把Runnable接口或Callable接口的实现类提交（调用submit方法）给ThreadPoolExecutor或ScheduledThreadPoolExecutor时，会返回一个FutureTask对象。
   
    《阿里巴巴Java开发手册》中强制线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险
    
    Executors 返回线程池对象的弊端如下:
    + FixedThreadPool 和 SingleThreadExecutor : 允许请求的队列长度为 Integer.MAX_VALUE,可能堆积 大量的请求，从而导致OOM。
    + CachedThreadPool 和 ScheduledThreadPool : 允许创建的线程数量为 Integer.MAX_VALUE ，可能 会创建大量线程，从而导致OOM。
    
    + 方式一：通过构造方法实现
    + 方式二：通过Executor 框架的工具类Executors来实现
      1. FixedThreadPool : 该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变。当有一个新的 任务提交时，线程池中若有空闲线程，则立即执行。若没有，则新的任务会被暂存在一个任务队列中，待有线 程空闲时，便处理在任务队列中的任务。
      2. SingleThreadExecutor: 方法返回一个只有一个线程的线程池。若多余一个任务被提交到该线程池，任务会 被保存在一个任务队列中，待线程空闲，按先入先出的顺序执行队列中的任务。
      3. CachedThreadPool: 该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但 若有空闲线程可以复用，则会优先使用可复用的线程。若所有线程均在工作，又有新的任务提交，则会创建新 的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池进行复用。
    
14. AQS的全称为(AbstractQueuedSynchronizer)，这个类在java.util.concurrent.locks包下面。 
    
    AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是 基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。
 
 
 15. Synchronized 和 ReenTrantLock 的对比
     ① 两者都是可重入锁
     
     两者都是可重入锁。“可重入锁”概念是：自己可以再次获取自己的内部锁。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，如果不可锁重入的话，就会造成死锁。同一个线程每次获取锁，锁的计数器都自增1，所以要等到锁的计数器下降为0时才能释放锁。
     
     ② synchronized 依赖于 JVM 而 ReenTrantLock 依赖于 API
     
     synchronized 是依赖于 JVM 实现的，前面我们也讲到了 虚拟机团队在 JDK1.6 为 synchronized 关键字进行了很多优化，但是这些优化都是在虚拟机层面实现的，并没有直接暴露给我们。ReenTrantLock 是 JDK 层面实现的（也就是 API 层面，需要 lock() 和 unlock 方法配合 try/finally 语句块来完成），所以我们可以通过查看它的源代码，来看它是如何实现的。
     
     ③ ReenTrantLock 比 synchronized 增加了一些高级功能
     
     相比synchronized，ReenTrantLock增加了一些高级功能。主要来说主要有三点：①等待可中断；②可实现公平锁；③可实现选择性通知（锁可以绑定多个条件）
     
     ReenTrantLock提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制。也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。
     
     ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。 ReenTrantLock默认情况是非公平的，可以通过 ReenTrantLock类的ReentrantLock(boolean fair)构造方法来制定是否是公平的。
     
     synchronized关键字与wait()和notify/notifyAll()方法相结合可以实现等待/通知机制，ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition() 方法。Condition是JDK1.5之后才有的，它具有很好的灵活性，比如可以实现多路通知功能也就是在一个Lock对象中可以创建多个Condition实例（即对象监视器），线程对象可以注册在指定的Condition中，从而可以有选择性的进行线程通知，在调度线程上更加灵活。 在使用notify/notifyAll()方法进行通知时，被通知的线程是由 JVM 选择的，用ReentrantLock类结合Condition实例可以实现“选择性通知” ，这个功能非常重要，而且是Condition接口默认提供的。而synchronized关键字就相当于整个Lock对象中只有一个Condition实例，所有的线程都注册在它一个身上。如果执行notifyAll()方法的话就会通知所有处于等待状态的线程这样会造成很大的效率问题，而Condition实例的signalAll()方法 只会唤醒注册在该Condition实例中的所有等待线程。
     
     如果你想使用上述功能，那么选择ReenTrantLock是一个不错的选择。
     
     ④ 性能已不是选择标准
     
     在JDK1.6之前，synchronized 的性能是比 ReenTrantLock 差很多。具体表示为：synchronized 关键字吞吐量岁线程数的增加，下降得非常严重。而ReenTrantLock 基本保持一个比较稳定的水平。我觉得这也侧面反映了， synchronized 关键字还有非常大的优化余地。后续的技术发展也证明了这一点，我们上面也讲了在 JDK1.6 之后 JVM 团队对 synchronized 关键字做了很多优化。JDK1.6 之后，synchronized 和 ReenTrantLock 的性能基本是持平了。所以网上那些说因为性能才选择 ReenTrantLock 的文章都是错的！JDK1.6之后，性能已经不是选择synchronized和ReenTrantLock的影响因素了！而且虚拟机在未来的性能改进中会更偏向于原生的synchronized，所以还是提倡在synchronized能满足你的需求的情况下，优先考虑使用synchronized关键字来进行同步！优化后的synchronized和ReenTrantLock一样，在很多地方都是用到了CAS操作。         
     
     
 16. Synchronized和Lock的区别
     1. 底层的区别,Synchronized依赖于jvm,Lock依赖于API
        Synchronized：底层使用指令码方式来控制锁的，映射成字节码指令就是增加来两个指令：monitorenter和monitorexit。当线程执行遇到monitorenter指令时会尝试获取内置锁，如果获取锁则锁计数器+1，如果没有获取锁则阻塞；当遇到monitorexit指令时锁计数器-1，如果计数器为0则释放锁。
        Lock底层是CAS乐观锁，依赖AbstractQueuedSynchronizer类，把所有的请求线程构成一个CLH队列。而对该队列的操作均通过Lock-Free（CAS）操作。
     2. Synchronized是关键字，内置语言实现，Lock是接口。
     3. Synchronized在线程发生异常时会自动释放锁，因此不会发生异常死锁。Lock异常时不会自动释放锁，所以需要在finally中实现释放锁。
     4. Lock是可以中断锁，Synchronized是非中断锁，必须等待线程执行完成释放锁
     5. Lock可以使用读锁提高多线程读效率。
     
 
 17. 乐观锁和悲观锁
     悲观锁：总是假设最坏的情况，认为竞争总是存在，每次拿数据的时候都认为会被修改，因此每次都会先上锁。其他线程阻塞等待释放锁。
     乐观锁：总是假设最好的情况，认为竞争总是不存在，每次拿数据的时候都认为不会被修改，因此不会先上锁，在最后更新的时候比较数据有无更新，可通过版本号或CAS实现。
     
     悲观锁：用于写比较多的情况，避免了乐观锁不断重试从而降低性能
     乐观锁：用于读比较多的情况，避免了不必要的加锁的开销
     
     乐观锁的问题
     1.ABA问题
     2.自旋时间CPU开销大
     3.JUC包下的原子类只能包含一个变量的原子操作，但是1.5之后的AtomicReference，能够保证引用对象的原子性。
  18. java线程同步的方式
      1. synchronized同步方法
      2. 同步代码块       
      3. 同步锁Lock，可重入锁
      4. juc原子类
      5. 使用特殊域变量(volatile)实现线程同步
      6. 使用局部变量实现线程同步ThreadLocal
      
#### 线程池
1. 常用配置参数
   1、默认值
           * corePoolSize=1
           * queueCapacity=Integer.MAX_VALUE
           * maxPoolSize=Integer.MAX_VALUE
           * keepAliveTime=60s
           * allowCoreThreadTimeout=false
           * rejectedExecutionHandler=AbortPolicy()
   
   2、如何来设置
           * 需要根据几个值来决定
               - tasks ：每秒的任务数，假设为500~1000
               - taskcost：每个任务花费时间，假设为0.1s
               - responsetime：系统允许容忍的最大响应时间，假设为1s
           * 做几个计算
               - corePoolSize = 每秒需要多少个线程处理？ 
                   * threadcount = tasks/(1/taskcost) =tasks*taskcout =  (500~1000)*0.1 = 50~100 个线程。corePoolSize设置应该大于50
                   * 根据8020原则，如果80%的每秒任务数小于800，那么corePoolSize设置为80即可
               - queueCapacity = (coreSizePool/taskcost)*responsetime
                   * 计算可得 queueCapacity = 80/0.1*1 = 800。意思是队列里的线程可以等待1s，超过了的需要新开线程来执行
                   * 切记不能设置为Integer.MAX_VALUE，这样队列会很大，线程数只会保持在corePoolSize大小，当任务陡增时，不能新开线程来执行，响应时间会随之陡增。
               - maxPoolSize = (max(tasks)- queueCapacity)/(1/taskcost)
                   * 计算可得 maxPoolSize = (1000-800)/10 = 20
                   * （最大任务数-队列容量）/每个线程每秒处理能力 = 最大线程数
               - rejectedExecutionHandler：根据具体情况来决定，任务不重要可丢弃，任务重要则要利用一些缓冲机制来处理
               - keepAliveTime和allowCoreThreadTimeout采用默认通常能满足
   
2. 拒绝策略
   线程池的拒绝策略，是指当任务添加到线程池中被拒绝，而采取的处理措施。
   当任务添加到线程池中之所以被拒绝，可能是由于：第一，线程池异常关闭。第二，任务数量超过线程池的最大限制。
   线程池共包括4种拒绝策略，它们分别是：AbortPolicy, CallerRunsPolicy, DiscardOldestPolicy和DiscardPolicy。线程池默认的处理策略是AbortPolicy！
   1. AbortPolicy         -- 当任务添加到线程池中被拒绝时，它将抛出 RejectedExecutionException 异常。在Executors类中默认采用的都是这种策略。
   2. CallerRunsPolicy    -- 当任务添加到线程池中被拒绝时，会在线程池当前正在运行的Thread线程池中处理被拒绝的任务。我们看这个处理方法中，我们看到这个策略显然不想放弃执行任务。那么就用当前的Executor进行执行。不过，这样也有弊端，那就是阻塞当前Executor线程，造成该线程池无法调度任务。
   3. DiscardOldestPolicy -- 当任务添加到线程池中被拒绝时，线程池会放弃等待队列中最旧的未处理任务，然后将被拒绝的任务添加到等待队列中。这个类实现了RejectedExecutionHandler接口中的方法。从源码中，我们可以看出这个类通过线程池获取到这个线程池的队列，然后调用poll方法将队列头部的任务拉黑。因为队列中最先进去的任务在队列头部。所以这个实现策略是将最老的任务拒绝掉。
   4. DiscardPolicy       -- 当任务添加到线程池中被拒绝时，线程池将丢弃被拒绝的任务。这个策略有点意思了，啥都没做。意思就是来了任务，我没法处理就不管了。也不会将任务加入workQueue中的。
   
   我们也可以通过实现RejectedExecutionHandler接口来定义自己的拒绝策略。
   

3. 饱和策略（就是拒绝策略）
   当核心线程corePoolSize满且阻塞队列也满时才会判断当前线程数是否小于最大线程数，并决定是否创建新线程，如果创建的线程总数大于maximumPoolSize的时候，就会触发RejectedExecetionHandler。
4. 怎么控制一个应用里面线程池的滥用
   通常，对于简单的应用，我们使用一个单例线程池即可，让应用中的所有task都使用同一个线程池，防止一些初级程序员在应用中随意创建线程池，导致线程资源吃紧，线程占用过多的资源。
   
   当应用中task比较复杂的时候，我们就需要使用分治的思想，对线程池进行隔离。
   比如有些是cpu密集型的，有些是IO密集型的；任务的重要程度也有轻重之分；任务的执行时间也有不同。我们需要对为这些任务建立不同的线程池，以此来提高效率。
   
5. 线程池滥用对下游业务的冲击如何防止      
6. 线程池调优
7. 常用策略
   Java通过Executors提供四种线程池，分别为：
   
   1. newCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
   
   2. newFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
   
   3. newScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。
   
   4. newSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。
8. 线程池类
   ThreadPoolExecutor类 -> AbstractExecutorService类 -> ExecutorService接口 -> Executor接口
   
   ThreadPoolExecutor的重要参数
   
   1. corePoolSize：核心线程数
   
   核心线程会一直存活，及时没有任务需要执行。
   
   当线程数小于核心线程数时，即使有线程空闲，线程池也会优先创建新线程处理。
   
   设置allowCoreThreadTimeout=true（默认false）时，核心线程会超时关闭。
   
   2. queueCapacity：任务队列容量（阻塞队列）
   
   当核心线程数达到最大时，新任务会放在队列中排队等待执行。
   
   3. maxPoolSize：最大线程数
   
   当线程数>=corePoolSize，且任务队列已满时。线程池会创建新线程来处理任务。
   
   当线程数=maxPoolSize，且任务队列已满时，线程池会拒绝处理任务而抛出异常。
   
   4. keepAliveTime：线程空闲时间
   
   当线程空闲时间达到keepAliveTime时，线程会退出，直到线程数量=corePoolSize。
   
   如果allowCoreThreadTimeout=true，则会直到线程数量=0。
   
   5. allowCoreThreadTimeout：允许核心线程超时
   
   6.rejectedExecutionHandler：任务拒绝处理器
   
   两种情况会拒绝处理任务：(1)当线程数已经达到maxPoolSize，切队列已满，会拒绝新任务。(2)当线程池被调用shutdown()后，会等待线程池里的任务执行完毕，再shutdown。如果在调用shutdown()和线程池真正shutdown之间提交任务，会拒绝新任务。线程池会调用rejectedExecutionHandler来处理这个任务。
   
   
   ThreadPoolExecutor执行顺序：
   1. 当线程数小于核心线程数时，创建线程。
   2. 当线程数大于等于核心线程数，且任务队列未满时，将任务放入任务队列。
   3. 当线程数大于等于核心线程数，且任务队列已满
      - 若线程数小于最大线程数，创建线程
      - 若线程数等于最大线程数，抛出异常，拒绝任务
       